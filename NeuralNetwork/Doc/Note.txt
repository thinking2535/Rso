* 시간이 지나도 기억해야 하는 어떠한 사실(뉴런)을 H 값을 이용해서 계속 활성화 되도록 하고,
  시간이 지나든, 어떠한 입력을 받는 이것에 의해서 비활성화 되도록 하는 것이 LSTM

// 신개념 뉴런 생성 /////////////////////////////
- 기본적으로 하나의 뉴런은 다수의 시냅스에 연결된 뉴런에 의해 활성화 되고, 하나라도 부족하면 활성화 되지 않는 원리
- 해당 레이어중 가장 활성화된 뉴런의 강도가 일정 수치 이하이면 해당 레이어에 새로운 뉴런 생성
- 전 레이어의 뉴런이 후 레이어의 뉴런을 활성화 시키면 전 레이어의 뉴런은 비활성화 되고, 반대면 활성화 유지
- 모든 레이어의 활성화 뉴런과 목표뉴런과 연결되며, 이 연결로 목표 뉴런이 활성화 됨
- 목표 뉴런이 활성화 되지 못하면 신규 레이어 생성?
/////////////////////////////////////////////////
문제
	- 뉴런, 레이어 수를 잘 설정 해야 하는 문제 -> 낮아진 w로 활성 전파가 시도되면 새로운 neuron 을 생성하여 모두활성 w 가 생성되도록 할것.
		1. 최초 무 에서 , 뉴런수를 스스로 늘려가도록 하고, 레이어는 없고, 매 단계마다 임시 기억리스트에 저장하고
		2. 한번 활성회차에 동일 뉴런을 또 거치지 않도록
		3. 뉴런에 연결된 일정 강도 이상의 시냅스로만 전파하고, 그 미만의 시냅스는 매번(또는 주기적으로) 삭제
		4. 

	- 학습률을 정확하게 설정해야 하는 문제
	- 학습량이 너무 많은 문제


* 망막세포역시 강한 빛을 받을 경우 잔상이 오래동안 남는 것처럼 뇌속의 뉴런역시 강한 자극을 받은 경우 

* 시퀀스를 통째로 기억하는 방법은 심플한데. 어떻게 긴 시간의 데이터(많은 데이터)를 기억하는 문제를 해결 할 수 있는가?
 -> 그것은 타임을 트리거로 처리? (시퀀스와 통합가능한가?)
   -> 지수적으로 증가하는 시간간격 뉴런을 사용?
    ?? 모든레이어에 RNN 개념필요?
* 중요 !!!!! RNN 시간이 흐르면서 뉴런 자동생성되도록
  ?? 언제 생성할 것인가? 필요시 생성해야 하는데, 


* 시간순서대로 일정 개수의 뉴런이 존재하고, 그 데이터들이 입력이 되는 구조가 rnn 의 기본 구조??
  이후 기억이 필요한 이벤트가 발생하면 Forward 방향으로 Capture 를 실행하고, 이때 활성화 되지않은 뉴런이 있는 Layer 에서 새로운 뉴런을 생성
* 특정 시점(또는 특정 요일 등 반복되는 어떠한 시점)에 이벤트 발생하는 것도, 특정 시점에 해당하는 뉴런에 이벤트를 출력으로 연결시킴으로써 해결

* RNN 의 장점은 입력데이터의 파동주기가 다르더라도 검출이 잘 된다는것.
  DNN으로 할 경우 주기의 차이가 클 수록 검출이 안됨.
 ->단 잊었던 과거 기억을 어떻게 회상할 수 있나?

** 중요 !!
 - 긴 미래를 예측하는 것은 단순히 일정시간 후의 것을 학습한 결과가 아니고, 
   짧은 미래를 예측하여, 이 예측된 값이 다시 입력으로 하여 또다시 미래를 예측하는 식으로, 여러단계의 것을 예측하여 긴 미래를 예측할 수 있도록 함.

* 어떻게 하면 차이점을 스스로 발견할 수 있을까?
  - 기존 알고리즘으로 가능?

* 언제 레이어를 증가시키고, 언제 동일레이어에서 뉴런을 생성할 것인가?


* Time Layer 는 길어지는 시간주기별로 가질것
* Time Layer로의 Value 복사시 무조건 하는것이 아니고 어떤 알고리즘에 의해 복사??
	- 이럴 필요가 있나? 어차피 해당 Time Layer 의 특정 뉴런이 영향이 없다면 Synapse 의 값이 0에 가까워 지고 자연스럽게 영향이 없어질텐데.








// Normal
auto Value = Weight * exp(-Factor * (In_ - Offset)*(In_ - Offset));
for (auto& i : _Outs)
	i->Load(Value);


// Sensor
auto Value = exp(-_Factor * (In_ - _Offset)*(In_ - _Offset));
for (auto& i : _Outs)
	i->Load(Value);


// Map 사용 인근 2개 노드 연상
void CNeuronIn::Load(double In_)
{
	auto it = _Sensors.lower_bound(In_);
	if (it != _Sensors.end())
	{
		it->second->Load(In_);

		if (it->first == In_)
			return;

		if (it != _Sensors.begin())
		{
			--it;
			it->second->Load(In_);
		}
	}
	else
	{
		auto rb = _Sensors.rbegin();
		if (rb != _Sensors.rend())
			rb->second->Load(In_);
	}
}



// Vector 방식 Sensor 구조
				auto v = _DataPtr[i] * double(_Neurons.size() - 1);
				auto a = size_t(v);
				auto b = a + 1;

				for (auto& i : _Neurons[a].Neurons)
				{
					i.Value += (b - v);
					itFront->emplace(&i);
				}

				auto bv = (v - a);
				if (bv > 0.0)
				{
					for (auto& i : _Neurons[a + 1].Neurons)
					{
						i.Value += bv;
						itFront->emplace(&i);
					}
				}
